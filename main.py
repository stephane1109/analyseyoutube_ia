# -*- coding: utf-8 -*-
from __future__ import annotations

import math
import os
import time
import traceback
from dataclasses import dataclass
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
import streamlit as st
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

st.set_page_config(page_title="YouTube IA et climat (Streamlit Cloud)", layout="wide")


@dataclass
class ParametresAPI:
    cle_api: str
    delai_requete: float = 0.1
    nb_tentatives: int = 5


def normaliser_requete(mot_cle: str, mode_hashtag: bool) -> str:
    q = (mot_cle or "").strip()
    if not q:
        return ""
    if mode_hashtag:
        return q if q.startswith("#") else f"#{q}"
    return q


def _safe_int(x) -> Optional[int]:
    try:
        if x is None:
            return None
        return int(x)
    except Exception:
        return None


def heuristique_indice_ia(titre: str, description: str) -> int:
    """
    Indicateur exploratoire basé sur le texte (signal secondaire).
    """
    t = ((titre or "") + " " + (description or "")).lower()
    mots = [
        "deepfake",
        "ai voice",
        "voice ai",
        "voix ia",
        "generated by ai",
        "généré par ia",
        "genere par ia",
        "midjourney",
        "stable diffusion",
        "suno",
        "elevenlabs",
        "heygen",
        "d-id",
    ]
    return 1 if any(m in t for m in mots) else 0


def normaliser_statut_ia_declare(val) -> str:
    if pd.isna(val):
        return "inconnu"
    if val is True:
        return "oui"
    if val is False:
        return "non"
    return "inconnu"


def requete_robuste(appel, nb_tentatives: int = 5, pause_initiale: float = 1.0):
    """
    Exécute un appel API avec retries simples (backoff).
    """
    pause = pause_initiale
    for tentative in range(nb_tentatives):
        try:
            return appel.execute()
        except HttpError:
            if tentative == nb_tentatives - 1:
                raise
            time.sleep(pause)
            pause *= 2


@st.cache_resource(show_spinner=False)
def creer_service_youtube(cle_api: str):
    """
    Service YouTube Data API v3.
    """
    return build("youtube", "v3", developerKey=cle_api, cache_discovery=False)


def tester_cle_api(service, params: ParametresAPI) -> str:
    """
    Test léger : on appelle une ressource peu coûteuse pour vérifier que la clé répond.
    """
    try:
        req = service.i18nLanguages().list(part="snippet")
        _ = requete_robuste(req, nb_tentatives=params.nb_tentatives)
        return "ok"
    except HttpError as e:
        code = getattr(e.resp, "status", None)
        return f"erreur_http_{code}"
    except Exception:
        return "erreur_inconnue"


def recuperer_playlist_uploads(service, channel_id: str, params: ParametresAPI) -> str:
    req = service.channels().list(part="contentDetails", id=channel_id, maxResults=1)
    rep = requete_robuste(req, nb_tentatives=params.nb_tentatives)
    items = rep.get("items", [])
    if not items:
        raise ValueError(f"Chaîne introuvable ou non accessible : {channel_id}")
    return items[0]["contentDetails"]["relatedPlaylists"]["uploads"]


def lister_videos_playlist(service, playlist_id: str, max_videos: int, params: ParametresAPI) -> List[str]:
    video_ids: List[str] = []
    page_token = None
    while True:
        req = service.playlistItems().list(
            part="contentDetails",
            playlistId=playlist_id,
            maxResults=min(50, max_videos - len(video_ids)),
            pageToken=page_token,
        )
        rep = requete_robuste(req, nb_tentatives=params.nb_tentatives)
        for it in rep.get("items", []):
            video_ids.append(it["contentDetails"]["videoId"])
            if len(video_ids) >= max_videos:
                return video_ids

        page_token = rep.get("nextPageToken")
        if not page_token:
            break

        if params.delai_requete > 0:
            time.sleep(params.delai_requete)

    return video_ids


def recuperer_details_videos(service, video_ids: List[str], params: ParametresAPI) -> pd.DataFrame:
    lignes: List[Dict] = []
    for i in range(0, len(video_ids), 50):
        lot = video_ids[i : i + 50]
        req = service.videos().list(
            part="snippet,status,statistics,contentDetails",
            id=",".join(lot),
            maxResults=50,
        )
        rep = requete_robuste(req, nb_tentatives=params.nb_tentatives)
        for v in rep.get("items", []):
            sn = v.get("snippet", {})
            stt = v.get("statistics", {})
            cd = v.get("contentDetails", {})
            status = v.get("status", {})

            lignes.append(
                {
                    "video_id": v.get("id"),
                    "channel_id": sn.get("channelId"),
                    "channel_title": sn.get("channelTitle"),
                    "titre": sn.get("title"),
                    "description": sn.get("description"),
                    "published_at": sn.get("publishedAt"),
                    "category_id": sn.get("categoryId"),
                    "duree_iso8601": cd.get("duration"),
                    "vues": _safe_int(stt.get("viewCount")),
                    "likes": _safe_int(stt.get("likeCount")),
                    "nb_commentaires": _safe_int(stt.get("commentCount")),
                    "containsSyntheticMedia": status.get("containsSyntheticMedia"),
                }
            )

        if params.delai_requete > 0:
            time.sleep(params.delai_requete)

    return pd.DataFrame(lignes)


def collecter_mode_chaines(
    service,
    df_chaines: pd.DataFrame,
    max_videos_par_chaine: int,
    params: ParametresAPI,
    progres_callback=None,
) -> pd.DataFrame:
    corpus = []
    total = len(df_chaines)

    for i, r in df_chaines.reset_index(drop=True).iterrows():
        channel_id = str(r["channel_id"]).strip()
        groupe = str(r["groupe"]).strip()

        if progres_callback:
            progres_callback((i + 1) / max(1, total), f"Collecte chaîne {i + 1}/{total} : {channel_id}")

        try:
            uploads = recuperer_playlist_uploads(service, channel_id, params)
            video_ids = lister_videos_playlist(service, uploads, max_videos_par_chaine, params)
            if not video_ids:
                continue

            df_vid = recuperer_details_videos(service, video_ids, params)
            if df_vid.empty:
                continue

            df_vid["groupe"] = groupe
            df_vid["mode_collecte"] = "chaines_seed"
            df_vid["requete_source"] = None
            df_vid["indice_ia_texte"] = df_vid.apply(
                lambda x: heuristique_indice_ia(x.get("titre"), x.get("description")),
                axis=1,
            )
            corpus.append(df_vid)

        except Exception:
            continue

    if not corpus:
        return pd.DataFrame()

    return pd.concat(corpus, ignore_index=True)


def collecter_mode_recherche(
    service,
    requete: str,
    max_resultats: int,
    params: ParametresAPI,
    region_code: Optional[str],
    langue: Optional[str],
    progres_callback=None,
) -> pd.DataFrame:
    video_ids: List[str] = []
    page_token = None

    while len(video_ids) < max_resultats:
        if progres_callback:
            progres_callback(
                len(video_ids) / max(1, max_resultats),
                f"Recherche : {len(video_ids)}/{max_resultats} vidéos",
            )

        req = service.search().list(
            part="id",
            q=requete,
            type="video",
            maxResults=min(50, max_resultats - len(video_ids)),
            pageToken=page_token,
            regionCode=region_code,
            relevanceLanguage=langue,
        )

        rep = requete_robuste(req, nb_tentatives=params.nb_tentatives)
        for it in rep.get("items", []):
            vid = it.get("id", {}).get("videoId")
            if vid:
                video_ids.append(vid)

        page_token = rep.get("nextPageToken")
        if not page_token:
            break

        if params.delai_requete > 0:
            time.sleep(params.delai_requete)

    video_ids = list(dict.fromkeys(video_ids))
    if not video_ids:
        return pd.DataFrame()

    df_vid = recuperer_details_videos(service, video_ids, params)
    if df_vid.empty:
        return df_vid

    df_vid["mode_collecte"] = "recherche"
    df_vid["requete_source"] = requete
    df_vid["indice_ia_texte"] = df_vid.apply(
        lambda x: heuristique_indice_ia(x.get("titre"), x.get("description")),
        axis=1,
    )
    if "groupe" not in df_vid.columns:
        df_vid["groupe"] = ""

    return df_vid


def proportion_ia_par_chaine(df: pd.DataFrame, mode_inconnu: str) -> pd.DataFrame:
    """
    mode_inconnu :
    "exclure" : proportion sur les vidéos où containsSyntheticMedia est renseigné
    "basse"   : inconnu = 0
    "haute"   : inconnu = 1
    """
    d = df.copy()

    def binaire(val):
        if pd.isna(val):
            return np.nan
        if val is True:
            return 1.0
        if val is False:
            return 0.0
        return np.nan

    d["ia_declare"] = d["containsSyntheticMedia"].apply(binaire)

    if mode_inconnu == "basse":
        d["ia_utilisee"] = d["ia_declare"].fillna(0.0)
    elif mode_inconnu == "haute":
        d["ia_utilisee"] = d["ia_declare"].fillna(1.0)
    else:
        d = d.dropna(subset=["ia_declare"]).copy()
        d["ia_utilisee"] = d["ia_declare"]

    if d.empty:
        return pd.DataFrame(columns=["channel_id", "channel_title", "groupe", "proportion_ia", "n_videos", "part_indice_ia_texte"])

    agg = d.groupby(["channel_id", "channel_title", "groupe"]).agg(
        proportion_ia=("ia_utilisee", "mean"),
        n_videos=("video_id", "count"),
        part_indice_ia_texte=("indice_ia_texte", "mean"),
    ).reset_index()

    return agg


def test_permutation_par_chaine(
    df_prop: pd.DataFrame,
    n_permutations: int,
    graine: int = 42,
    progres_callback=None,
) -> Dict:
    dfp = df_prop.dropna(subset=["proportion_ia", "groupe"]).copy()
    dfp["groupe"] = dfp["groupe"].astype(str).str.strip()
    groupes = sorted([g for g in dfp["groupe"].unique().tolist() if g != ""])
    if len(groupes) != 2:
        raise ValueError("Le test de permutation nécessite exactement 2 groupes non vides dans la colonne 'groupe'.")

    g1, g2 = groupes[0], groupes[1]
    x = dfp["proportion_ia"].to_numpy(dtype=float)
    labels = dfp["groupe"].to_numpy(dtype=str)

    masque1 = labels == g1
    masque2 = labels == g2
    if masque1.sum() == 0 or masque2.sum() == 0:
        raise ValueError("Chaque groupe doit contenir au moins une chaîne.")

    obs = float(x[masque1].mean() - x[masque2].mean())

    rng = np.random.default_rng(graine)
    compte = 0

    bloc = 500
    nb_blocs = int(math.ceil(n_permutations / bloc))

    for b in range(nb_blocs):
        debut = b * bloc
        fin = min(n_permutations, (b + 1) * bloc)

        for _ in range(debut, fin):
            perm = rng.permutation(labels)
            diff = float(x[perm == g1].mean() - x[perm == g2].mean())
            if abs(diff) >= abs(obs):
                compte += 1

        if progres_callback:
            progres_callback((b + 1) / max(1, nb_blocs), f"Test de permutation : {fin}/{n_permutations}")

    p_value = (compte + 1) / (n_permutations + 1)
    return {
        "difference_moyennes": float(obs),
        "p_value": float(p_value),
        "groupe_1": g1,
        "groupe_2": g2,
        "n_permutations": int(n_permutations),
    }


def dataframe_telechargeable(df: pd.DataFrame, nom_fichier: str, cle: str):
    csv = df.to_csv(index=False, encoding="utf-8")
    st.download_button(
        label=f"Télécharger {nom_fichier}",
        data=csv.encode("utf-8"),
        file_name=nom_fichier,
        mime="text/csv",
        key=cle,
    )


def interface_principale():
    st.title("YouTube : marqueurs IA et comparaison climatosceptique versus climat")

    st.write(
        "Cette application récupère des vidéos YouTube et exploite le champ `containsSyntheticMedia` lorsqu’il est disponible. "
        "Si le champ n’est pas renseigné, l’information doit être traitée comme inconnue. "
        "L’analyse est faite au niveau des chaînes : on calcule une proportion par chaîne, puis on compare deux groupes."
    )

    with st.expander("Mode diagnostic (utile si l’écran reste vide ou si une action échoue)", expanded=False):
        mode_diag = st.checkbox("Afficher les détails techniques des erreurs", value=False)
        st.caption("Si un appel YouTube échoue (clé invalide, clé restreinte, quota), tu verras le message ici.")
    if "mode_diag" not in st.session_state:
        st.session_state["mode_diag"] = False
    st.session_state["mode_diag"] = bool(mode_diag)

    st.subheader("0) Clé API YouTube Data API v3")
    cle_api = st.text_input("Clé API (champ masqué)", value="", type="password").strip()

    if not cle_api:
        st.warning("Saisis une clé API pour activer la collecte.")
        st.stop()

    delai = st.slider("Délai entre requêtes (secondes)", 0.0, 1.0, 0.1, 0.05)
    params = ParametresAPI(cle_api=cle_api, delai_requete=float(delai), nb_tentatives=5)

    try:
        service = creer_service_youtube(cle_api)
    except Exception as e:
        st.error("Impossible d’initialiser le service YouTube.")
        if st.session_state["mode_diag"]:
            st.exception(e)
        st.stop()

    if st.button("Tester la clé API"):
        statut = tester_cle_api(service, params)
        if statu
