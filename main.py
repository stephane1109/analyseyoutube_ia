# -*- coding: utf-8 -*-
from __future__ import annotations

import time
from dataclasses import dataclass
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
import streamlit as st
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError


st.set_page_config(page_title="YouTube : tableau des 3 marqueurs IA", layout="wide")


@dataclass
class ParametresAPI:
    cle_api: str
    delai_requete: float = 0.1
    nb_tentatives: int = 5


def normaliser_requete(mot_cle: str, mode_hashtag: bool) -> str:
    q = (mot_cle or "").strip()
    if not q:
        return ""
    if mode_hashtag:
        return q if q.startswith("#") else f"#{q}"
    return q


def requete_robuste(appel, nb_tentatives: int = 5, pause_initiale: float = 1.0):
    pause = pause_initiale
    for tentative in range(nb_tentatives):
        try:
            return appel.execute()
        except HttpError:
            if tentative == nb_tentatives - 1:
                raise
            time.sleep(pause)
            pause *= 2


def creer_service_youtube(cle_api: str):
    return build("youtube", "v3", developerKey=cle_api, cache_discovery=False)


def _safe_int(x) -> Optional[int]:
    try:
        if x is None:
            return None
        return int(x)
    except Exception:
        return None


def heuristique_indice_ia(titre: str, description: str) -> int:
    """
    Indice secondaire basé sur le texte (non probant, mais utile à l’exploration).
    """
    t = ((titre or "") + " " + (description or "")).lower()
    mots = [
        "deepfake", "ai voice", "voice ai", "voix ia",
        "generated by ai", "généré par ia", "genere par ia",
        "midjourney", "stable diffusion", "suno", "elevenlabs", "heygen", "d-id",
    ]
    return 1 if any(m in t for m in mots) else 0


def normaliser_oui_non_inconnu(valeur: object) -> str:
    """
    Normalise vers {oui, non, inconnu}.
    Accepte booléens, None, et quelques variantes textuelles.
    """
    if valeur is None:
        return "inconnu"
    if isinstance(valeur, float) and np.isnan(valeur):
        return "inconnu"
    if valeur is True:
        return "oui"
    if valeur is False:
        return "non"

    s = str(valeur).strip().lower()
    if s in ["oui", "yes", "true", "1", "present", "présent", "présente", "present(e)"]:
        return "oui"
    if s in ["non", "no", "false", "0", "absent", "absente", "absent(e)"]:
        return "non"
    if s in ["inconnu", "unknown", "na", "n/a", "none", "null", ""]:
        return "inconnu"
    return "inconnu"


def enrichir_marqueurs(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ajoute/normalise les colonnes des 3 marqueurs :
    marqueur_api  : dérivé de status.containsSyntheticMedia (API YouTube)
    marqueur_c2pa : à renseigner par import CSV ou édition manuelle
    marqueur_ui   : à renseigner par import CSV ou édition manuelle
    """
    d = df.copy()

    if "containsSyntheticMedia" in d.columns:
        d["marqueur_api"] = d["containsSyntheticMedia"].apply(normaliser_oui_non_inconnu)
    else:
        d["marqueur_api"] = "inconnu"

    if "marqueur_c2pa" not in d.columns:
        d["marqueur_c2pa"] = "inconnu"
    d["marqueur_c2pa"] = d["marqueur_c2pa"].apply(normaliser_oui_non_inconnu)

    if "marqueur_ui" not in d.columns:
        d["marqueur_ui"] = "inconnu"
    d["marqueur_ui"] = d["marqueur_ui"].apply(normaliser_oui_non_inconnu)

    if "indice_ia_texte" not in d.columns:
        d["indice_ia_texte"] = d.apply(lambda x: heuristique_indice_ia(x.get("titre"), x.get("description")), axis=1)

    return d


def recuperer_playlist_uploads(service, channel_id: str, params: ParametresAPI) -> str:
    req = service.channels().list(part="contentDetails", id=channel_id, maxResults=1)
    rep = requete_robuste(req, nb_tentatives=params.nb_tentatives)
    items = rep.get("items", [])
    if not items:
        raise ValueError(f"Chaîne introuvable ou non accessible : {channel_id}")
    return items[0]["contentDetails"]["relatedPlaylists"]["uploads"]


def lister_videos_playlist(service, playlist_id: str, max_videos: int, params: ParametresAPI) -> List[str]:
    video_ids: List[str] = []
    page_token = None

    while True:
        req = service.playlistItems().list(
            part="contentDetails",
            playlistId=playlist_id,
            maxResults=min(50, max_videos - len(video_ids)),
            pageToken=page_token,
        )
        rep = requete_robuste(req, nb_tentatives=params.nb_tentatives)

        for it in rep.get("items", []):
            video_ids.append(it["contentDetails"]["videoId"])
            if len(video_ids) >= max_videos:
                return video_ids

        page_token = rep.get("nextPageToken")
        if not page_token:
            break

        if params.delai_requete > 0:
            time.sleep(params.delai_requete)

    return video_ids


def recuperer_details_videos(service, video_ids: List[str], params: ParametresAPI) -> pd.DataFrame:
    lignes: List[Dict] = []

    for i in range(0, len(video_ids), 50):
        lot = video_ids[i:i + 50]
        req = service.videos().list(
            part="snippet,status,statistics,contentDetails",
            id=",".join(lot),
            maxResults=50
        )
        rep = requete_robuste(req, nb_tentatives=params.nb_tentatives)

        for v in rep.get("items", []):
            sn = v.get("snippet", {})
            stt = v.get("statistics", {})
            cd = v.get("contentDetails", {})
            status = v.get("status", {})

            lignes.append({
                "video_id": v.get("id"),
                "channel_id": sn.get("channelId"),
                "channel_title": sn.get("channelTitle"),
                "titre": sn.get("title"),
                "description": sn.get("description"),
                "published_at": sn.get("publishedAt"),
                "category_id": sn.get("categoryId"),
                "duree_iso8601": cd.get("duration"),
                "vues": _safe_int(stt.get("viewCount")),
                "likes": _safe_int(stt.get("likeCount")),
                "nb_commentaires": _safe_int(stt.get("commentCount")),
                "containsSyntheticMedia": status.get("containsSyntheticMedia"),
            })

        if params.delai_requete > 0:
            time.sleep(params.delai_requete)

    return pd.DataFrame(lignes)


def collecter_mode_chaines(service, df_chaines: pd.DataFrame, max_videos_par_chaine: int, params: ParametresAPI, progres_callback=None) -> pd.DataFrame:
    corpus = []
    total = len(df_chaines)

    for i, r in df_chaines.reset_index(drop=True).iterrows():
        channel_id = str(r["channel_id"]).strip()

        if progres_callback:
            progres_callback((i + 1) / max(1, total), f"Collecte chaîne {i + 1}/{total} : {channel_id}")

        try:
            uploads = recuperer_playlist_uploads(service, channel_id, params)
            video_ids = lister_videos_playlist(service, uploads, max_videos_par_chaine, params)
            if not video_ids:
                continue

            df_vid = recuperer_details_videos(service, video_ids, params)
            if df_vid.empty:
                continue

            df_vid["mode_collecte"] = "chaines_seed"
            df_vid["requete_source"] = None
            df_vid["indice_ia_texte"] = df_vid.apply(lambda x: heuristique_indice_ia(x.get("titre"), x.get("descri
